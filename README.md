# Flow Log Parser

## Description

This program parses a file containing flow log data and maps each row to a tag based on a lookup table. The lookup table is defined as a CSV file with three columns: `dstport`, `protocol`, and `tag`. Each combination of `dstport` and `protocol` determines what tag is applied to a log entry.

The program supports **version 2** flow logs only, based on the default AWS flow log format. It generates an output file that contains:
1. The count of matches for each tag.
2. The count of matches for each port/protocol combination.

## Assumptions

1. **Custom log formats** or **non-default versions** of flow logs are not supported.
2. The program assumes **TCP/UDP/ICMP** as the protocol types for port and protocol mapping.
3. The program processes the flow logs line by line, which is efficient enough for large files up to 10 MB.
4. The program only processes **version 2** flow logs. Any logs with a different version are skipped.
5. The input files (`flow_log.txt` and `lookup.csv`) are in plain ASCII text format.
6. The program assumes a fixed log format with 14 fields. If the log format is incorrect or malformed, the line is skipped.
7. The tags are case-insensitive, meaning that protocols like `TCP` and `tcp` are treated as the same.
8. The flow log file can be up to **10 MB** in size, and the lookup table can contain up to **10,000 mappings**.
9. The program handles flow log entries with `NODATA` and `SKIPDATA` statuses, which are logged but skipped during processing.

## Folder Structure

```
ILLUMIO-FLOWLOG-PARSER/
│
├── data/
│   ├── flow_log.txt      # Input file containing flow log data
│   └── lookup.csv        # Input file containing port, protocol, and tag mappings
│
├── output/
│   └── output.txt        # Output file generated by the program
│
├── src/
│   ├── main.py           # Main flow log parsing script
│   └── __init__.py       # Package marker
│
├── tests/
│   ├── test_flow_log.py  # Unit test script for testing functions
│   └── __init__.py       # Package marker
│
└── README.md             # This README file
```



## How to Run the Program

### Prerequisites

- Python 3.x installed on your system.
- No additional external libraries are required, only built-in Python libraries like `csv`, `os`, `logging`, and `unittest`.

### Instructions

1. **Download the Project**:
   - Clone or download the project folder `ILLUMIO-FLOWLOG-PARSER`.

2. **Prepare Input Files**:
   - Place your `flow_log.txt` and `lookup.csv` files inside the `data/` directory.
   - Example contents of `flow_log.txt` and `lookup.csv` are provided in the `data/` folder.

3. **Run the Program**:
   - Navigate to the `src/` directory and run the `main.py` script:
     ```bash
     python main.py
     ```

4. **Output**:
   - After successful execution, the output will be written to `output/output.txt`.
   - The output file will contain two sections:
     1. **Tag Counts**: The number of flow log entries matched to each tag.
     2. **Port/Protocol Combination Counts**: The number of flow log entries matched to each (port, protocol) combination.

### Example of Output

Tag Counts:
Tag,Count
sv_P1,2
email,3
Untagged,9

Port/Protocol Combination Counts:
Port,Protocol,Count
25,tcp,1
110,tcp,1
993,tcp,1
143,tcp,1
1024,tcp,1
80,tcp,1



## Testing

### Unit Tests

Unit tests are provided in the `tests/test_flow_log.py` file to validate the following:
- Parsing of the lookup table.
- Processing of valid and malformed flow log lines.
- Correct handling of "NODATA" and "SKIPDATA" log entries.
- Generation of output with accurate tag counts and port/protocol counts.

### Running the Tests

To run the tests, navigate to the root project directory and execute the following command:
```bash
python -m unittest discover -s tests
```

This will automatically discover and run all unit tests in the `tests/` directory.

## Logging

The program uses Python's built-in `logging` module to record important events, warnings, and errors:

- **Warnings** are logged for malformed flow log lines or unknown protocols.
- **Info** logs are created for skipped `NODATA` or `SKIPDATA` records.
- **Errors** are logged for missing or corrupted input files.

All logs are printed to the console for easy monitoring during execution.

<!-- ## Notes

1. **Custom log formats** or **non-default versions** of flow logs are not supported.
2. The program assumes **TCP/UDP/ICMP** as the protocol types for port and protocol mapping.
3. The program processes the flow logs line by line, which is efficient enough for large files up to 10 MB. -->
